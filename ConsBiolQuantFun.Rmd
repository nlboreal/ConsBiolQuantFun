--- 
title: "Introduction to Quantitative Techniques in R for Conservation Biology"
author: "Dr. Yolanda Wiersma"
date: "`r Sys.Date()`"
site: bookdown::bookdown_site
output: bookdown::gitbook
documentclass: book
bibliography: [book.bib, packages.bib]
biblio-style: apalike
link-citations: yes
github-repo: rstudio/ConsBiolQuantFun
description: "This is a manual for the Quantitative Techniques Module in BIOL 4651/7944 (Conservation in Practice)"
---

# Introduction

Biology, including ecology and conservation, is becoming increasingly quantitative. Familiarity with a range of statistical tools (frequentist, multivariate, Bayesian) is expected. Many researchers draw on quantitative methods; whether it is process or mathematical modelling, programming, bioinformatics, or bioeconomic analyses. We will only touch on key concepts in quantitative methods; in-depth training would require multiple full-semester courses. 

In the process of increasing quantitative skills across the Biology curriculum, we have prepared an online guide for using R, that is designed for new users, and as a reference document for all Biology students. You can access it [here](https://ahurford.github.io/quant-guide-all-courses/). 
In this three-week module, we will carry out a few exercise that mimics some of the quantitative skills that you need to be a successful conservation biologist. These include:

1. Data management (with an introduction to the ```dplyr``` package)
1. Plotting data effectively (with an introduction to the ```ggplot2``` package)
1. Univariate and multivariate statistical analysis (with an introduction to the ```vegan``` package)





```{r include=FALSE}
# automatically create a bib database for R packages
knitr::write_bib(c(
  .packages(), 'bookdown', 'knitr', 'rmarkdown'
), 'packages.bib')
```

<!--chapter:end:index.Rmd-->

# Data for this manual {#data}

We are using three data sets from the Mid-Atlantic Coastal Plain (MACP). An analysis with these data is described in a paper by @McMullin2019. The data sets are available as CSV files on Brightspace and are as described briefly below. 

* MACPsites.csv: a database of site attributes (215 rows; 1 row per site). Attributes are coded as
    + ER: Ecoregion name
    + VEG: Vegetation type
    + PPT: Average annual precipitation (in mm)
    + TEMP: Average annual temperature (in degrees Celsius)
    + ELEV: Elevation above sea level (in m)

* MACPspp.csv: a species by site matrix. Sites are in rows (215 rows; 1 row per site) and species are columns (599). Full names of species associated with each code are in the Supplemental material to the @McMullin2019 paper. 

* MACPtraits.csv: a species by traits matrix. Species are rows (599 rows; 1 row per species) with 4 columns of trait categories. Traits are
    + Photobiont: indicates which algae or cyanobacteria is the photobiont partner for that lichen
    + Reproductive.Mode: indicates how the lichen reproduceds
    + Reproductive.Structure: indicates what kind of reprodcutive structure(s) that species has
    + Substrate: indicates what kind of substrate this species is usually found on
    








<!--chapter:end:01-intro.Rmd-->

# Part 1. Data Wrangling {#dataMgmt}

This section teaches some tricks and tips for data wrangling using the ```dplyr``` package. It reviews some of the more detailed introduction to ```dplyr``` from BIOL 1002 labs. If you would like to review the lab manual for BIOL 1002, you can access it [here](https://jakep962.github.io/Biol_1002/index.html).

A useful "cheatsheet" to print out and hang by your desk for this module is the ```dplyr``` [cheatsheet](https://rstudio.com/wp-content/uploads/2015/02/data-wrangling-cheatsheet.pdf)


## Step 1 - Install package and read in files

* install and load the package ```dplyr``` (if you don't remember how to do this, refer to Section 4.10 of the [Biology R Guide](https://ahurford.github.io/quant-guide-all-courses/rintro.html#r-packages)

```{r echo = FALSE, message = FALSE}
#install.packages("dplyr")
library(dplyr)
```

* read in the three data sets. The code is given below, you can chose to give the dataframes different names, but for ease of following along it would be wise to use the same as here.

```{r}
MACPsites <- read.csv("MACPsites.csv")
MACPspp <- read.csv("MACPspp.csv")
MACPtraits <- read.csv("MACPtraits.csv")
```

## Step 2: Create a new column and add it to a dataframe

Use the ```mutate``` function in ```dplyr``` to create a column which sums all the species at that site, and writie it to a new dataframe called MACPspp_sum. Note that this is a row-wise function and that I am using the ```pipes``` tool (denoted by the ```%>%``` symbol). If you would like to review using pipes, see Section 2.1.5 of the manual for [BIOL1002](https://jakep962.github.io/Biol_1002/week1.html#lab1).

```{r}
MACPspp_sum <- MACPspp %>%
  rowwise() %>%
  mutate(sppRich = sum(c_across(ABRhyp:XYLnig)))
```

## Step 3: Querying and filtering the data

Use the ```filter``` function in ``dplyr`` to select only those sites that have more than 80 species and use this to create a new dataframe called MACPhotspots. Check Section 2.1.1 of the Manual for [BIOL1002](https://jakep962.github.io/Biol_1002/week1.html#lab1) to review the code. 

**HAND IN** Then try using a function  to find out what the highest species richness is across all sites (**HINT** another word for highest richness is ```max``` richness). Describe what function you used (a code snippet would be fine!)


```{r echo = FALSE, results = 'hide'}
MACPhotspots <- filter(MACPspp_sum, sppRich > 80)
max(MACPhotspots$sppRich)
```

## Step 4. Grouping and Joining Data

Because both the MACPsites data and the MACPspp data are arranged in rows, with one row per site, we can combine them into one dataframe that contains both the species and the environment data. We can do it like this:

```{r}
MACPall <- inner_join(MACPsites, MACPspp_sum, by = "site")
```

**HAND IN**: How would you confirm that you have done this correctly (there are different ways)?

Sometimes we might want to group and summarize the data in different ways. For example, we might want to group the data by Ecoregion and then see what the mean richness is per ecoregion, to see if some ecoregions have higher richness than others. In the next section we will use these summary data to make some graphs.

```{r}
EcoR_spp <- group_by(MACPall, ER)

EcoR_spp_mean <- summarize(EcoR_spp, mean_rich = mean(sppRich))
EcoR_spp_se <- summarize(EcoR_spp, se_rich = sd(sppRich))
```

## What to hand in for Part 1.

Summarize the results from above where it says **HAND IN**. As well, in one or two sentences explain the difference between the ```select``` , ```filter``` and ```mutate``` functions in the package ```dplyr```.

<!--chapter:end:02-dataMgmt.Rmd-->

# Part 2. Making Effective Graphs {#graphs}

In this section, we will make a few different types of graphs, using the package ```ggplot2```. You'll also spend some time thinking about the best way to visualize different types of data.

You will need to install and load the package ```ggplot2``` and you might want to keep the ggplot2 [cheatsheet](https://rstudio.com/wp-content/uploads/2016/11/ggplot2-cheatsheet-2.1.pdf) handy.

```{r echo = FALSE, message = FALSE}
#install.packages("ggplot2")
library(ggplot2)
```

We'll start by making a simple barplot of mean species richness using the dataframes we created at the end of \@ref(dataMgmt). The package ggplot works with datafames and not vectors (as is the case when using the ```plot``` function in ```baseR```). The syntax of ggplot is also very elegant in that you can "layer" on data and themes to an existing plot using the ```+``` symbol at the end of each line -- we made use of this when we employed ```ggplot2``` to do GIS-type mapping in the previous [Module](https://nlboreal.github.io/ConservationGIS/) for this course).

```{r}
ggplot(data = EcoR_spp_mean) +
  geom_col(mapping= aes(x = ER, y = mean_rich))
```

You might notice that the text labels on the X-axis are not well-placed. We can adjust this by adding a ```theme``` that specifies the angle at which to display the text. Note that the first two lines of the code chunk below are identical to the chunk above, but with the ```+``` sign added at the end, so that we can add a line of code to add a ```theme``` function.

```{r}
ggplot(data = EcoR_spp_mean) +
  geom_col(mapping= aes(x = ER, y = mean_rich)) +
  theme(axis.text.x = element_text(angle = 90))
```

To add error bars, one way we could do that is to first add the standard error we calculated in \@ref(dataMgmt) to the dataframe that ```ggplot2``` is using, again using a ```dplyr``` function.

```{r}
EcoR_spp_meanse <- inner_join(EcoR_spp_mean, EcoR_spp_se, "ER")
```

Then we simply add another ```geom``` function to the code snippet above, and adjust the ```data = ``` code to reflect the new set with the standard error column added.

```{r}
ggplot(data = EcoR_spp_meanse) +
  geom_col(mapping= aes(x = ER, y = mean_rich)) +
  geom_errorbar(mapping = aes(x = ER, ymin = mean_rich, ymax = mean_rich + se_rich)) + 
  theme(axis.text.x = element_text(angle = 90))
```

## Your assignment for Part 2

1. Pick two variables in one of the datasets we're using here that would be best shown as a scatterplot. Feel free to join or group data from any of the 3 datasets to pracitse your data wrangling skills. Try adjusting the symbology and axis labels for maximum effect. Hand in a copy of your code and the finished figure. Justify why a scatterplot is an appropriate way to display these data. 

1. **For graduate students (and ambitious undergrads)** In addition to the above step, pick a graph type in ```ggplot2``` that you have never created before (but that perhaps is a way you may want to visualize your own data for your graduate work), and pick the appropriate data from one or more of the sets avaialable here to create a figure. Hand in a copy of your code and the finished figure. Justify why the data chosen fit this kind of figure well. 


<!--chapter:end:03-plots.Rmd-->

# Part 3. Statistical Analysis {#stats}

You will need to install and load package ```vegan```.

```{r echo = FALSE, message = FALSE}
#install.packages("vegan")
library(vegan)
```

## Univariate Analysis

 We will be doing a simple Generalized Linear Model (GLM). You could easily do an entire course on GLMs, so this is not even going to begin to scratch the surface of what there is to learn about this type of statistical analysis.
 
In the paper by @McMullin2019, the authors examined which lichen sites and species might be most threatened by sea level rise. They did not look for other patterns of species distribution. Here we will test whether lichen richness follows the pattern predicted by the latitudinal species gradient that has been observed for other species.

Here is the code to create a GLM called ```lat_test``` (short for "latitude test"). We're simply testing whether latitude ("Lat") explains species richness with a linear function.
```{r}
lat_test <- glm(sppRich ~ Lat, data = MACPall)
```

To see the model output, type ```summary(lat_test)```.

It's always important to check that your model doesn't violate assumptions of normality. You can assess this by inspecting the ratio of the null deviance to residual deviance in the model summary.

You can do this by plotting the model fits. Do this with the code ```plot(lat_test)```. You will see plots of 1) residuals vs. fitted data; 2) a Q-Q plot; 3) Scale-location plot; 4) Residuals vs. Leverage.

Click the links here to read about how to interpret the [Residuals vs Fitted plot](https://stats.stackexchange.com/questions/76226/interpreting-the-residuals-vs-fitted-values-plot-for-verifying-the-assumptions); the [Q-Q plot](https://stats.stackexchange.com/questions/101274/how-to-interpret-a-qq-plot). If your model does not meet the assumptions of normality, you may need to use a different error structure (e.g., Poisson, logNormal). Going into the whys and hows of that is beyond the scope of this course. The Q-Q plot fit here for ```lat_test``` is slightly skewed but we're going to accept it.

To make a scatterplot of the data with the line of best fit included, use the code below. Note the new function ```predict.glm``` which calls the model we built (```lat-test```) and builds a predictive line across the range of x-values in our plot. The code chunk below also demonstrates how to add customized x and y axis labels (third "layer" in the ggplot2 code). In the first line (```geom_point``` function), there is a demonstration of  how to colour code the points by one of the attributes in the data base (in this case ```ER``` for Ecoregion) AND how to use ```position=jitter``` to add some slight noise to the data that allows you to see more points by minimizing overlap between points. This makes your graph slightly less accurate on a very fine scale, but enables you to see broader scale patterns. Both of these can be very useful functions.

```{r}
ggplot(data = MACPall) +
  geom_point(mapping = aes(x = Lat, y = sppRich, colour = ER), position = "jitter") +
  geom_line(mapping = aes(x = Lat, y = predict.glm(lat_test)), size = 1) +
  labs(x = "latitude", y = "lichen species richness")
```



## Multivariate Analysis

Multivariate analysis refers to statistical analyses of more than one variable at a time. Again, one could easily fill an entire course on the topic of multivariate statistics, so we're only going to demonstrate what one kind of multivariate analysis looks like using R. We're going to do a type of ordination, called a Non-metric multidimensional scaling (or NMDS). There are many types of ordination analysis out there - you may have heard of some of them, some of these are Principal Components Analysis (PCA), Canonical Components Analysis (CCA).

An ordination simply summarizes multivariate data and projects into a lower dimensional space - usually across two axes. It can be a useful way to see intrinsic patterns in complex data sets, or to simplify data before doing different analyses. 

You will need to load the ```vegan``` package to do this analysis.

To do the NMDS ordination, we use the function ```metaMDS```. We'll apply it to the species data set. Recall that this is a dataset with 215 rows (one row per site) and 599 species. This is a fairly large data set. The ordination will allow us to see whether certain species are closer together in data space, and if this corresponds to some of the site-level attributes.

Before we do this, we need to manipulate the ```MACPspp``` data frame so that it only includes the species data. You could use a tool from the ```dplyr``` package, or since we know the sites are in the first column and there are 600 columns total in ```MACPspp``` we can use a simple ```baseR``` funcction:

```{r}
spp <- MACPspp[,2:600]
```

Here is the code to do the ordination of ```spp``` as well as plot it. The default in the plot settings is to use black circles for sites and red ```+``` signs for species.

```{r, message = FALSE}
ordination_spp <- metaMDS(spp)
plot(ordination_spp)
```

We can adjust this using the function ```display```. Play around with the code below to see how you can change the plot.

```{r}
plot(ordination_spp, display = "sites")
text(ordination_spp, display = "spec", cex = 0.7, col = "blue")
```

The ```text``` function adds the species names. There are so many that they become illegible. You could try adjusting the font size, or if this were your own data, you might apply 2-letter species codes, if possible.

Often we want to layer other information on an ordination to better see pattern. For example, we might want to add convex hulls around the site points that are from the same ecoregion. This will let us see whether some ecoregions have species that are unique to them (the hull will be isolated from other hulls) or if two or more ecoregions have similar species composition (the hulls will have a lot of overlap).

Before we do that, we need to strip the "sites" column from the ```MACPsites``` dataframe so we have just the environmental variables. We could use the baseR method we did above to create ```spp```, or you could use the ```select``` function from the ```dplyr``` package.

```{r}
env <- select(MACPsites, ER, VEG, PPT, TEMP, ELEV)
```

Then specify to create convex hulls using the ecoregion field (```ER```) from ```env```:

```ordihull(ordination_spp, env$ER, col = 1:4, label = TRUE)```


Try the above code, and then see if you can modify it to create convex hulls by vegetation type. 

If you can't see the hulls because the text labels are too big, change ```label = TRUE``` to ```label = FALSE``` and run the code again.

Another data visualization might be to use ellipses instead of convex hulls. You can try it with this code:

```ordiellipse(ordination_spp, env$ER, col = 1:4, draw = "polygon")```

Finally, we might want to do a test to see how different environmental variables at the sites load onto to the two axis of our ordination. This can start to tell us how what's happening at the sites might be influencing the species pattern(s).

```ord.fit <- envfit(ordination_spp ~ ELEV + PPT + TEMP, data = env, perm = 999)```

To see the test output, type ```ord.fit```

To plot the fits of elevation, temperature and precipitation on the ordination, use these to lines of code.

```plot(ordination_spp)```
```plot(ord.fit, col = "black")```


## Your assignment for Part 3

1. Describe what you can conclude about the effect of latitude on species richness for the mid-Atlantic Coastal Plain. Is the fit significant? Are there issues with the data that might affect the inferences drawn from the statistical analysis? 

1. What interpretation can you make from the final ordination plot we made here?

1. Think about a possible hypothesis that @McMullin2019 could have tested with these data, but did not. 
* Write out the hypothesis in words and include a prediction
* Sketch a "toy graph" of how you expect the data to look if the hypothesis is supported
* Identify what kind of statistical test you will apply
* Describe how what steps you need to take with these data to execute the steps (i.e., do you need to do any data wrangling first?). A flow chart or bullet points would be a good way to do this.
* Execute the test. Include a copy of the code, the statistical output and a short interpretation of the hypothesis test.

**For graduate students**: Do the above step twice (i.e., test two different hypotheses). Challenge yourself to try a new test that you may not have done before. 


<!--chapter:end:04-statistics.Rmd-->

`r if (knitr:::is_html_output()) '
# References {-} 


@article{McMullin2019,
  title = {Risk assessment and conservation strategies for rare lichen species and communities threatened by sea-level rise in the Mid-Atlantic Coastal Plain},
  author = {McMullin RT, Wiersma YF, Newmaster SG, Lendemer JC}, 
  year = {2019},
  journal = {Biological Conservation},
  volume = {239}, 
  doi = {https://doi.org/10.1016/j.biocon.2019.108281},
}


<!--chapter:end:05-references.Rmd-->

